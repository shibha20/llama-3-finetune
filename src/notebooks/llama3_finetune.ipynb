{"metadata":{"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30732,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"- Fine-tune multi-lingual - with both Hindi and Nepali\n- Fine tune with Hindi run inference on Nepali \n- Fine tune with Nepali run inference on Hindi\n- Fine tune with Nepali run inference on Nepali\n- Fine tune with Hindi run inference on Hindi","metadata":{}},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient","metadata":{"execution":{"iopub.status.busy":"2024-06-16T20:18:41.620893Z","iopub.execute_input":"2024-06-16T20:18:41.621274Z","iopub.status.idle":"2024-06-16T20:18:41.635228Z","shell.execute_reply.started":"2024-06-16T20:18:41.621234Z","shell.execute_reply":"2024-06-16T20:18:41.634222Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"user_secrets = UserSecretsClient()\ntoken = user_secrets.get_secret(\"GITHUB_KEY\")","metadata":{"execution":{"iopub.status.busy":"2024-06-16T20:18:43.231871Z","iopub.execute_input":"2024-06-16T20:18:43.232262Z","iopub.status.idle":"2024-06-16T20:18:43.419872Z","shell.execute_reply.started":"2024-06-16T20:18:43.232232Z","shell.execute_reply":"2024-06-16T20:18:43.419068Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"!git clone https://{token}@github.com/shreeya-dhakal/llama-3-finetune.git","metadata":{"execution":{"iopub.status.busy":"2024-06-16T20:18:44.796193Z","iopub.execute_input":"2024-06-16T20:18:44.796542Z","iopub.status.idle":"2024-06-16T20:18:49.280805Z","shell.execute_reply.started":"2024-06-16T20:18:44.796514Z","shell.execute_reply":"2024-06-16T20:18:49.279584Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Cloning into 'llama-3-finetune'...\nremote: Enumerating objects: 104, done.\u001b[K\nremote: Counting objects: 100% (104/104), done.\u001b[K\nremote: Compressing objects: 100% (81/81), done.\u001b[K\nremote: Total 104 (delta 50), reused 62 (delta 15), pack-reused 0\u001b[K\nReceiving objects: 100% (104/104), 27.40 MiB | 18.39 MiB/s, done.\nResolving deltas: 100% (50/50), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"%%capture\n!mamba install --force-reinstall aiohttp -y\n!pip install -U \"xformers<0.0.26\" --index-url https://download.pytorch.org/whl/cu121\n!pip install \"unsloth[kaggle-new] @ git+https://github.com/unslothai/unsloth.git\"\n\n# Temporary fix for https://github.com/huggingface/datasets/issues/6753\n!pip install datasets==2.16.0 fsspec==2023.10.0 gcsfs==2023.10.0","metadata":{"execution":{"iopub.status.busy":"2024-06-16T20:18:49.282926Z","iopub.execute_input":"2024-06-16T20:18:49.283238Z","iopub.status.idle":"2024-06-16T20:23:48.679336Z","shell.execute_reply.started":"2024-06-16T20:18:49.283208Z","shell.execute_reply":"2024-06-16T20:23:48.678016Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"import os\nimport wandb\n\nos.environ[\"WANDB_PROJECT\"]=\"llama-finetune-nepali\"\nos.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"\nwandb_token = user_secrets.get_secret(\"WANDB_KEY\")\nwandb.login(key= wandb_token)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T20:28:59.260017Z","iopub.execute_input":"2024-06-16T20:28:59.260817Z","iopub.status.idle":"2024-06-16T20:29:03.752066Z","shell.execute_reply.started":"2024-06-16T20:28:59.260776Z","shell.execute_reply":"2024-06-16T20:29:03.750905Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"from datasets import load_dataset, load_metric\nimport sys\nimport os\nsys.path.append('/kaggle/working/llama-3-finetune/src/')\nfrom data.data_sampler import sample_data\nfrom unsloth import FastLanguageModel\nimport torch\nimport re","metadata":{"execution":{"iopub.status.busy":"2024-06-16T20:29:09.336130Z","iopub.execute_input":"2024-06-16T20:29:09.336918Z","iopub.status.idle":"2024-06-16T20:29:37.263306Z","shell.execute_reply.started":"2024-06-16T20:29:09.336885Z","shell.execute_reply":"2024-06-16T20:29:37.262502Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n","output_type":"stream"},{"name":"stderr","text":"2024-06-16 20:29:23.689276: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-06-16 20:29:23.689421: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-06-16 20:29:23.947179: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"split_ratio = 0.2\nseed = 42","metadata":{"execution":{"iopub.status.busy":"2024-06-16T20:29:37.264733Z","iopub.execute_input":"2024-06-16T20:29:37.265323Z","iopub.status.idle":"2024-06-16T20:29:37.269407Z","shell.execute_reply.started":"2024-06-16T20:29:37.265295Z","shell.execute_reply":"2024-06-16T20:29:37.268370Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"dataset_name = \"CohereForAI/aya_dataset\"\naya_dataset = load_dataset(dataset_name)\ndataset_type = \"aya\"","metadata":{"execution":{"iopub.status.busy":"2024-06-16T20:41:18.630835Z","iopub.execute_input":"2024-06-16T20:41:18.631719Z","iopub.status.idle":"2024-06-16T20:41:19.833847Z","shell.execute_reply.started":"2024-06-16T20:41:18.631678Z","shell.execute_reply":"2024-06-16T20:41:19.832825Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"aya_nepali = aya_dataset.filter(lambda example: example['language'] == \"Nepali\")\naya_nepali","metadata":{"execution":{"iopub.status.busy":"2024-06-16T20:41:20.435223Z","iopub.execute_input":"2024-06-16T20:41:20.435567Z","iopub.status.idle":"2024-06-16T20:41:20.449881Z","shell.execute_reply.started":"2024-06-16T20:41:20.435539Z","shell.execute_reply":"2024-06-16T20:41:20.448896Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['inputs', 'targets', 'language', 'language_code', 'annotation_type', 'user_id'],\n        num_rows: 4002\n    })\n    test: Dataset({\n        features: ['inputs', 'targets', 'language', 'language_code', 'annotation_type', 'user_id'],\n        num_rows: 0\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"aya_hindi = aya_dataset.filter(lambda example: example['language'] == \"Hindi\")\naya_hindi","metadata":{"execution":{"iopub.status.busy":"2024-06-16T20:41:23.284388Z","iopub.execute_input":"2024-06-16T20:41:23.284771Z","iopub.status.idle":"2024-06-16T20:41:23.299626Z","shell.execute_reply.started":"2024-06-16T20:41:23.284743Z","shell.execute_reply":"2024-06-16T20:41:23.298664Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['inputs', 'targets', 'language', 'language_code', 'annotation_type', 'user_id'],\n        num_rows: 1153\n    })\n    test: Dataset({\n        features: ['inputs', 'targets', 'language', 'language_code', 'annotation_type', 'user_id'],\n        num_rows: 0\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"lang_multi = \"Nepali\"\naya_nepali_train, _ = sample_data(dataset_name, dataset_type, split_ratio, seed, output_dir=None, lang_multi=lang_multi)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T20:41:28.880244Z","iopub.execute_input":"2024-06-16T20:41:28.880902Z","iopub.status.idle":"2024-06-16T20:41:33.638364Z","shell.execute_reply.started":"2024-06-16T20:41:28.880871Z","shell.execute_reply":"2024-06-16T20:41:33.637344Z"},"trusted":true},"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/202362 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4337c37fcee4eac8a8fa595025dae3b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/1750 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"890c42959beb45feb0dd2ec145725a27"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/4002 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5ea71249978542db951b3624845e9c55"}},"metadata":{}}]},{"cell_type":"code","source":"lang_multi = \"Hindi\"\naya_hindi_train, _ = sample_data(dataset_name, dataset_type, split_ratio, seed, output_dir=None, lang_multi=lang_multi)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T20:41:33.639919Z","iopub.execute_input":"2024-06-16T20:41:33.640212Z","iopub.status.idle":"2024-06-16T20:41:38.059428Z","shell.execute_reply.started":"2024-06-16T20:41:33.640187Z","shell.execute_reply":"2024-06-16T20:41:38.058395Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/202362 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1eef2b0fdd9441d3981ce16081a1b351"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/1750 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"232d0189996f4558863f9d8fe4f2a9db"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/1153 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"026c8fac952e4c2594faa89089a0e25b"}},"metadata":{}}]},{"cell_type":"code","source":"dataset_name = \"Saugatkafley/alpaca-nepali-sft\"\nalpaca_nepali = load_dataset(dataset_name)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T20:42:05.241348Z","iopub.execute_input":"2024-06-16T20:42:05.241751Z","iopub.status.idle":"2024-06-16T20:42:05.818969Z","shell.execute_reply.started":"2024-06-16T20:42:05.241719Z","shell.execute_reply":"2024-06-16T20:42:05.818081Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"alpaca_nepali_filtered = alpaca_nepali.filter(lambda example: example['output'] is not None and example['output'] != \"\")\nalpaca_nepali_filtered = alpaca_nepali_filtered.filter(lambda example: example['instruction'] != \"\" and example['instruction'] is not None)\nalpaca_nepali_filtered = alpaca_nepali_filtered.filter(lambda example: example['input'] is not None)\nalpaca_nepali_train, _ = sample_data(alpaca_nepali_filtered, \"alpaca\", split_ratio, seed, output_dir=None, lang_multi=None)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T20:42:08.400723Z","iopub.execute_input":"2024-06-16T20:42:08.401404Z","iopub.status.idle":"2024-06-16T20:42:08.923618Z","shell.execute_reply.started":"2024-06-16T20:42:08.401367Z","shell.execute_reply":"2024-06-16T20:42:08.922227Z"},"trusted":true},"execution_count":27,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[27], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m alpaca_nepali_filtered \u001b[38;5;241m=\u001b[39m alpaca_nepali_filtered\u001b[38;5;241m.\u001b[39mfilter(\u001b[38;5;28;01mlambda\u001b[39;00m example: example[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstruction\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m example[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minstruction\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m alpaca_nepali_filtered \u001b[38;5;241m=\u001b[39m alpaca_nepali_filtered\u001b[38;5;241m.\u001b[39mfilter(\u001b[38;5;28;01mlambda\u001b[39;00m example: example[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m----> 4\u001b[0m alpaca_nepali_train, _ \u001b[38;5;241m=\u001b[39m \u001b[43msample_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43malpaca_nepali_filtered\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43malpaca\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit_ratio\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang_multi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/kaggle/working/llama-3-finetune/src/data/data_sampler.py:19\u001b[0m, in \u001b[0;36msample_data\u001b[0;34m(dataset_name, dataset_type, split_ratio, seed, output_dir, lang_multi)\u001b[0m\n\u001b[1;32m     15\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for language: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlang_multi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m random\u001b[38;5;241m.\u001b[39mseed(seed)\n\u001b[0;32m---> 19\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dataset_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maya\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     22\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mfilter(\u001b[38;5;28;01mlambda\u001b[39;00m example: example[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlanguage\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m lang_multi)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/datasets/load.py:2501\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(path, name, data_dir, data_files, split, cache_dir, features, download_config, download_mode, verification_mode, ignore_verifications, keep_in_memory, save_infos, revision, token, use_auth_token, task, streaming, num_proc, storage_options, trust_remote_code, **config_kwargs)\u001b[0m\n\u001b[1;32m   2499\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m data_files \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data_files:\n\u001b[1;32m   2500\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmpty \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata_files\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_files\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. It should be either non-empty or None (default).\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDATASET_STATE_JSON_FILENAME\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mexists():\n\u001b[1;32m   2502\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou are trying to load a dataset that was saved using `save_to_disk`. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2504\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease use `load_from_disk` instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2505\u001b[0m     )\n\u001b[1;32m   2507\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m streaming \u001b[38;5;129;01mand\u001b[39;00m num_proc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/pathlib.py:960\u001b[0m, in \u001b[0;36mPath.__new__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m Path:\n\u001b[1;32m    959\u001b[0m     \u001b[38;5;28mcls\u001b[39m \u001b[38;5;241m=\u001b[39m WindowsPath \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnt\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m PosixPath\n\u001b[0;32m--> 960\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_from_parts\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    961\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flavour\u001b[38;5;241m.\u001b[39mis_supported:\n\u001b[1;32m    962\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot instantiate \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m on your system\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    963\u001b[0m                               \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,))\n","File \u001b[0;32m/opt/conda/lib/python3.10/pathlib.py:594\u001b[0m, in \u001b[0;36mPurePath._from_parts\u001b[0;34m(cls, args)\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    590\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_from_parts\u001b[39m(\u001b[38;5;28mcls\u001b[39m, args):\n\u001b[1;32m    591\u001b[0m     \u001b[38;5;66;03m# We need to call _parse_args on the instance, so as to get the\u001b[39;00m\n\u001b[1;32m    592\u001b[0m     \u001b[38;5;66;03m# right flavour.\u001b[39;00m\n\u001b[1;32m    593\u001b[0m     \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__new__\u001b[39m(\u001b[38;5;28mcls\u001b[39m)\n\u001b[0;32m--> 594\u001b[0m     drv, root, parts \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parse_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    595\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drv \u001b[38;5;241m=\u001b[39m drv\n\u001b[1;32m    596\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_root \u001b[38;5;241m=\u001b[39m root\n","File \u001b[0;32m/opt/conda/lib/python3.10/pathlib.py:578\u001b[0m, in \u001b[0;36mPurePath._parse_args\u001b[0;34m(cls, args)\u001b[0m\n\u001b[1;32m    576\u001b[0m     parts \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39m_parts\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 578\u001b[0m     a \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    579\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(a, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    580\u001b[0m         \u001b[38;5;66;03m# Force-cast str subclasses to str (issue #21127)\u001b[39;00m\n\u001b[1;32m    581\u001b[0m         parts\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mstr\u001b[39m(a))\n","\u001b[0;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not DatasetDict"],"ename":"TypeError","evalue":"expected str, bytes or os.PathLike object, not DatasetDict","output_type":"error"}]},{"cell_type":"code","source":"dataset_name = load_dataset(\"iamshnoo/alpaca-cleaned-hindi\")","metadata":{"execution":{"iopub.status.busy":"2024-06-16T20:33:56.881979Z","iopub.execute_input":"2024-06-16T20:33:56.882400Z","iopub.status.idle":"2024-06-16T20:33:59.432421Z","shell.execute_reply.started":"2024-06-16T20:33:56.882368Z","shell.execute_reply":"2024-06-16T20:33:59.431389Z"},"trusted":true},"execution_count":15,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/497 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e7cd958321a6416d90137cc1c2736708"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/31.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0acb924e843340f18b07333bcae2d1ef"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/51760 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74af1c0d382242b8af7dffad5d5c933d"}},"metadata":{}},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input', 'instruction', 'output'],\n        num_rows: 51760\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"alpaca_hindi_filtered = alpaca_hindi.filter(lambda example: example['output'] is not None and example['output'] != \"\")\nalpaca_hindi_filtered = alpaca_hindi_filtered.filter(lambda example: example['instruction'] != \"\" and example['instruction'] is not None)\nalpaca_hindi_filtered = alpaca_hindi_filtered.filter(lambda example: example['input'] is not None)\nalpaca_hindi_train, _ = sample_data(alpaca_hindi_filtered, \"alpaca\", split_ratio, seed, output_dir=None, lang_multi=None)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T20:34:02.117556Z","iopub.execute_input":"2024-06-16T20:34:02.118527Z","iopub.status.idle":"2024-06-16T20:34:05.516837Z","shell.execute_reply.started":"2024-06-16T20:34:02.118493Z","shell.execute_reply":"2024-06-16T20:34:05.515784Z"},"trusted":true},"execution_count":16,"outputs":[{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/51760 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"18503fc3f74542c2aae01256c5b9efa1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/51760 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aaf9f2d553c34876ad24fdbd8e717470"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Filter:   0%|          | 0/51760 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7726a18e6a65418181dfaf0141bb4a6d"}},"metadata":{}},{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['input', 'instruction', 'output'],\n        num_rows: 51760\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"#Neapli\nprompt = \"\"\"Below is an instruction in Hindi that describes a task, paired with an input also in hindi that provides further context. Write a response in Hindi that appropriately completes the request.\n\n### Instruction:\n{}\n\n### Input:\n{}\n\n### Response:\n{}\"\"\"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\ndtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\nload_in_4bit = True\n\nmodel, tokenizer = FastLanguageModel.from_pretrained(\n    model_name = \"unsloth/llama-3-8b-bnb-4bit\",\n    max_seq_length = max_seq_length,\n    dtype = dtype,\n    load_in_4bit = load_in_4bit,\n    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#LoRA\nmodel = FastLanguageModel.get_peft_model(\n    model,\n    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n    lora_alpha = 16,\n    lora_dropout = 0, # Supports any, but = 0 is optimized\n    bias = \"none\",    # Supports any, but = \"none\" is optimized\n    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n    random_state = 3407,\n    use_rslora = False,  # We support rank stabilized LoRA\n    loftq_config = None, # And LoftQ\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n\n\ndef formatting_prompts_func(examples):\n    instructions = examples[\"instruction\"]\n    inputs       = examples[\"input\"]\n    outputs      = examples[\"output\"]\n    texts = []\n    for instruction, input, output in zip(instructions, inputs, outputs):\n        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n        texts.append(text)\n    return { \"text\" : texts, }\npass\n\n\nfrom datasets import load_dataset\ndataset = load_dataset(\"iamshnoo/alpaca-cleaned-bengali\", split = \"train\")\ndataset = dataset.map(formatting_prompts_func, batched = True,)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from trl import SFTTrainer\nfrom transformers import TrainingArguments\n\ntrainer = SFTTrainer(\n    model = model,\n    tokenizer = tokenizer,\n    train_dataset = dataset,\n    dataset_text_field = \"text\",\n    max_seq_length = max_seq_length,\n    dataset_num_proc = 2,\n    packing = False, # Can make training 5x faster for short sequences.\n    args = TrainingArguments(\n        per_device_train_batch_size = 2,\n        gradient_accumulation_steps = 4,\n        warmup_steps = 5,\n        max_steps = 1000,                #### Setting max_steps for 1000. (1-1000)\n        learning_rate = 2e-4,\n        fp16 = not torch.cuda.is_bf16_supported(),\n        bf16 = torch.cuda.is_bf16_supported(),\n        logging_steps = 1,\n        save_steps=500,                 ### Checkpoint will be save after every 500 steps\n        optim = \"adamw_8bit\",\n        weight_decay = 0.01,\n        report_to=\"wandb\", \n        run_name=\"llama3_alpaca_nep\", \n        lr_scheduler_type = \"linear\",\n        seed = 3407,\n        output_dir = \"outputs_alpaca_nep\",   # Saving the checkpoints to outputs folder\n    ),\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trainer_stats = trainer.train()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wandb.finish()","metadata":{},"execution_count":null,"outputs":[]}]}